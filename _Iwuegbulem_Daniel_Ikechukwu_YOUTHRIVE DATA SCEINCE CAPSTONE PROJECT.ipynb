{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUTHRIVE DATA SCEINCE CAPSTONE PROJECT\n",
    "INCOME LEVEL PREDICTION\n",
    "Project timeline: 2 weeks (10 th , September – 22 th September\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "Project Overview\n",
    "\n",
    "My name is Iwuegbulem Daniel, and I am currently enrolled in a Data Science program with Youthrive. This report is part of my capstone project, which focuses on applying data science techniques to real-world problems. The aim of this project is to develop a machine learning model that predicts whether a person’s income exceeds $50K per year based on census data. By exploring various data features, cleaning and preparing the data, and implementing predictive algorithms, the project seeks to provide insights and accurate predictions that can help understand the key factors influencing income levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method of importing matplotlib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting style\n",
    "\n",
    "style.available\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "\n",
    "income_data = pd.read_csv(\"income_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame:\",income_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review data types and summary statistics to identify numerical and categorical variables and also convert variable to appropriate datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first few rows of the dataset and check basic information\n",
    "data_head = income_data.head()\n",
    "\n",
    "data_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = income_data.info()\n",
    "\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "income_data.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for categorical columns\n",
    "income_data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to 'category' data type\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    income_data[column] = income_data[column].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "income_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns, e.g., 'fnlwgt,education-num and relationship' (modify based on your findings)\n",
    "income_data = income_data.drop(['fnlwgt'], axis=1)\n",
    "\n",
    "# Verify the changes\n",
    "income_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = income_data.drop(['relationship'], axis=1)\n",
    "income_data = income_data.drop(['education-num'], axis=1)\n",
    "\n",
    "\n",
    "# Verify the changes\n",
    "income_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = income_data.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns with missing values\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fill missing values for categorical columns with the mode (most frequent value)\n",
    "for column in ['workclass', 'occupation', 'native-country']:\n",
    "    income_data[column].fillna(income_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Verify if there are still missing values\n",
    "income_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary Libraries for Visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of income levels\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='income', data=income_data)\n",
    "plt.title('Income Distribution')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "#Insight: This will show the proportion of people with income <= $50K and > $50K, giving insight into the balance of the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution based on income\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=income_data, x='age', hue='income', multiple='stack', kde=True)\n",
    "plt.title('Age Distribution by Income')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Insight: This will show whether older individuals tend to earn more than $50K, helping to understand if age is a significant factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the relationship between education and income\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(y='education', hue='income', data=income_data, order=income_data['education'].value_counts().index)\n",
    "plt.title('Education Level vs Income')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Education Level')\n",
    "plt.show()\n",
    "#Insight: This will provide insights into how education affects income. Higher education levels are likely associated with higher income levels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting workclass vs income\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(y='workclass', hue='income', data=income_data, order=income_data['workclass'].value_counts().index)\n",
    "plt.title('Workclass vs Income')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Workclass')\n",
    "plt.show()\n",
    "#Insight: This will reveal how different types of employment (e.g., private sector, government) are related to income. For example, self-employed individuals might be more likely to earn above $50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting hours-per-week by income level\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='income', y='hours-per-week', data=income_data)\n",
    "plt.title('Hours Worked Per Week by Income Level')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Hours per Week')\n",
    "plt.show()\n",
    "#Insight: This boxplot will show the range of hours worked for both income groups, helping to determine if working longer hours is correlated with earning a higher income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "Handling Missing Values:\n",
    "\n",
    "Address missing values in the dataset if any, using appropriate imputation\n",
    "methods to ensure a complete dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = income_data.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_values[missing_values > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for categorical columns with the mode\n",
    "for column in ['workclass', 'occupation', 'native-country']:\n",
    "    income_data[column].fillna(income_data[column].mode()[0], inplace=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if there are still missing values\n",
    "income_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to encode\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                       'race', 'sex', 'native-country', 'income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-Hot Encoding for categorical columns\n",
    "income_data_encoded = pd.get_dummies(income_data, columns=categorical_columns[:-1], drop_first=True)\n",
    "\n",
    "# Display the first few rows of the new dataset with encoded variables\n",
    "income_data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the income column is a binary categorical variable (<=50K and >50K), we can use label\n",
    "# Label Encoding for the target column 'income'\n",
    "income_data_encoded['income'] = income_data['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "# Display the first few rows of the dataset after encoding\n",
    "income_data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation ensures that all categorical variables are now in a numerical format, making the dataset suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling:\n",
    "o Standardize/normalize numerical features to ensure they are on a comparable\n",
    "scale, which can improve the performance of many machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Scaling\n",
    "Here is the code to apply Standardization using StandardScaler from the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler for standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_columns = ['age', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling to the numerical columns\n",
    "income_data_encoded[numerical_columns] = scaler.fit_transform(income_data_encoded[numerical_columns])\n",
    "\n",
    "# Display the scaled dataset\n",
    "income_data_encoded.head()\n",
    "#Explanation:\n",
    "#StandardScaler: This scales the numerical features so that they have a mean of 0 and a standard deviation of 1.\n",
    "#The transformation is applied only to the numerical columns to ensure they are on a comparable scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#You can check the summary statistics of the scaled features to ensure that the scaling was applied correctly.\n",
    "# Verify the scaling by checking summary statistics\n",
    "income_data_encoded[numerical_columns].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "By standardizing (or normalizing) the numerical features, you ensure that your model is not biased by differences in the scale of the features. This is especially important for algorithms sensitive to scale, such as k-nearest neighbors or gradient-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split:\n",
    "o Split the dataset into training and testing sets to evaluate the model&#39;s performance\n",
    "on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Required Libraries\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically split the data into 70-80% for training and 20-30% for testing. Here's how to do it:\n",
    "\n",
    "Features (X): These are the independent variables.\n",
    "Target (y): This is the dependent variable (in this case, the income column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (X) and the target (y)\n",
    "X = income_data_encoded.drop('income', axis=1)\n",
    "y = income_data_encoded['income']\n",
    "\n",
    "# Perform the train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shape of the resulting datasets\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X: All the features except for the target (income).\n",
    "y: The target column (income), which indicates whether income is <=50K or >50K.\n",
    "test_size=0.2: This means 20% of the data will be used for testing, and 80% for training.\n",
    "random_state=42: Ensures reproducibility, meaning that the split will be the same each time you run the code.\n",
    "stratify=y: This ensures that the proportion of <=50K and >50K is maintained in both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the Split\n",
    "#To ensure that the dataset is properly split, you can check the size of the training and test sets.\n",
    "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now split into training and testing sets. This allows you to train your machine learning model on the training data and evaluate it on the testing data, giving you a clear picture of how the model performs on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries for Models\n",
    "First, import the necessary libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Different Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries for Models\n",
    "First, import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using a Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize the Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Train the model on the training set\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Make predictions on the test set\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "y_pred_prob_dt = decision_tree.predict_proba(X_test)[:, 1]  # For ROC-AUC and ROC Curve\n",
    "\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "tree_accuracy = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Accuracy: {tree_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate model performance\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, y_pred_prob_dt)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Decision Tree Accuracy: {accuracy_dt:.4f}\")\n",
    "print(f\"Decision Tree Precision: {precision_dt:.4f}\")\n",
    "print(f\"Decision Tree Recall: {recall_dt:.4f}\")\n",
    "print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")\n",
    "print(f\"Decision Tree ROC-AUC Score: {roc_auc_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# the Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, None],  # Depth of the tree\n",
    "    'min_samples_split': [2, 10, 20],    # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 5, 10],      # Minimum samples at a leaf node\n",
    "    'criterion': ['gini', 'entropy']     # Criteria to measure the quality of a split\n",
    "}\n",
    "\n",
    "#  Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "#Train the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Get the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "#  Evaluate the optimized model on the test set\n",
    "y_pred_best_tree = best_tree.predict(X_test)\n",
    "y_pred_prob_best_tree = best_tree.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy_best_tree = accuracy_score(y_test, y_pred_best_tree)\n",
    "precision_best_tree = precision_score(y_test, y_pred_best_tree)\n",
    "recall_best_tree = recall_score(y_test, y_pred_best_tree)\n",
    "f1_best_tree = f1_score(y_test, y_pred_best_tree)\n",
    "roc_auc_best_tree = roc_auc_score(y_test, y_pred_prob_best_tree)\n",
    "\n",
    "# Print the performance metrics of the optimized Decision Tree\n",
    "print(f\"Optimized Decision Tree Accuracy: {accuracy_best_tree:.4f}\")\n",
    "print(f\"Optimized Decision Tree Precision: {precision_best_tree:.4f}\")\n",
    "print(f\"Optimized Decision Tree Recall: {recall_best_tree:.4f}\")\n",
    "print(f\"Optimized Decision Tree F1 Score: {f1_best_tree:.4f}\")\n",
    "print(f\"Optimized Decision Tree ROC-AUC Score: {roc_auc_best_tree:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob_dt)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Decision Tree (AUC = {roc_auc_dt:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Decision Tree')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using K-Nearest Neighbors (KNN) to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Initialize the KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # n_neighbors can be tuned\n",
    "\n",
    "# Train the KNN model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_prob_knn = knn.predict_proba(X_test)[:, 1]  # For ROC-AUC and ROC Curve\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the performance\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_pred_prob_knn)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"KNN Accuracy: {accuracy_knn:.4f}\")\n",
    "print(f\"KNN Precision: {precision_knn:.4f}\")\n",
    "print(f\"KNN Recall: {recall_knn:.4f}\")\n",
    "print(f\"KNN F1 Score: {f1_knn:.4f}\")\n",
    "print(f\"KNN ROC-AUC Score: {roc_auc_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Step 2: Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],  # Different values for the number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Whether to weight all points equally or by distance\n",
    "    'metric': ['euclidean', 'manhattan']  # The distance metric\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "#  Train the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "#  Evaluate the optimized model on the test set\n",
    "y_pred_best_knn = best_knn.predict(X_test)\n",
    "y_pred_prob_best_knn = best_knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)\n",
    "precision_best_knn = precision_score(y_test, y_pred_best_knn)\n",
    "recall_best_knn = recall_score(y_test, y_pred_best_knn)\n",
    "f1_best_knn = f1_score(y_test, y_pred_best_knn)\n",
    "roc_auc_best_knn = roc_auc_score(y_test, y_pred_prob_best_knn)\n",
    "\n",
    "# Print the performance metrics of the optimized KNN\n",
    "print(f\"Optimized KNN Accuracy: {accuracy_best_knn:.4f}\")\n",
    "print(f\"Optimized KNN Precision: {precision_best_knn:.4f}\")\n",
    "print(f\"Optimized KNN Recall: {recall_best_knn:.4f}\")\n",
    "print(f\"Optimized KNN F1 Score: {f1_best_knn:.4f}\")\n",
    "print(f\"Optimized KNN ROC-AUC Score: {roc_auc_best_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob_knn)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"KNN (AUC = {roc_auc_knn:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - KNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_knn, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "forest_accuracy = accuracy_score(y_test, y_pred_forest)\n",
    "print(f\"Random Forest Accuracy: {forest_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve performance, you can optimize the hyperparameters of the model using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters for Random Forest: {best_params}\")\n",
    "\n",
    "# Evaluate the tuned model\n",
    "y_pred_grid = grid_search.predict(X_test)\n",
    "grid_accuracy = accuracy_score(y_test, y_pred_grid)\n",
    "print(f\"Tuned Random Forest Accuracy: {grid_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training multiple models, we can evaluate their performance using metrics such as accuracy,\n",
    "precision, recall, F1 score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making prediction\n",
    "y_pred = random_forest.predict(X_test)  # Predictions (0 or 1)\n",
    "y_pred_prob = random_forest.predict_proba(X_test)[:, 1]  # Probabilities for ROC-AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Print the ROC-AUC score\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#ROC Curve: Plots the true positive rate (TPR) against the false positive rate (FPR) for different threshold values, providing a measure of the model’s ability to distinguish between the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#Confusion Matrix: Visualizes the true positives, true negatives, false positives, and false negatives, helping you understand the model's prediction distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "summary of key insights and trends that can be derived from a typical Exploratory Data Analysis on census data for predicting income levels\n",
    "\n",
    "1. Education Level and Income:\n",
    "Higher education levels (e.g., Bachelors, Masters, Doctorate) are strongly associated with higher income.\n",
    "Individuals with only high school education or below tend to have a lower probability of earning more than 50K.\n",
    "2. Occupation and Income:\n",
    "Certain occupations, like Executives/Managers and Professional/Specialty roles, have a higher concentration of individuals earning above 50K.\n",
    "Service-related jobs and laborers are predominantly in the lower income category (<50K).\n",
    "3. Age and Income:\n",
    "There's a clear upward trend showing that older individuals, particularly those between 35-55 years old, are more likely to earn above 50K.\n",
    "Income seems to plateau or slightly decrease after the age of 60, likely due to retirement or reduced working hours.\n",
    "4. Marital Status and Income:\n",
    "Married individuals, particularly those who are married and living together , are more likely to earn above 50K.\n",
    "Single individuals and those who are divorced or separated are more represented in the lower-income group.\n",
    "5. Gender and Income Disparity:\n",
    "Men are more likely to earn above 50K than women, highlighting a potential gender income gap.\n",
    "The proportion of women earning more than 50K is significantly lower than that of men in similar age and occupation brackets.\n",
    "6. Work Hours and Income:\n",
    "Individuals working 40-50 hours per week are more likely to earn above 50K.\n",
    "Those working fewer than 30 hours per week or above 60 hours per week are predominantly in the lower income category.\n",
    "7. Capital Gain and Loss:\n",
    "Capital gain and capital loss are strong indicators of high income, with individuals reporting significant capital gains being much more likely to earn above 50K.\n",
    "Those with no capital gain or capital loss are predominantly in the lower income category.\n",
    "8. Native Country and Income:\n",
    "People born in the United States tend to have a higher probability of earning above 50K compared to immigrants.\n",
    "Certain countries, such as Canada or Western European nations, also have a slight increase in representation in the higher income group compared to other regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discuss the performance of your machine learning model, its effectiveness in predicting income level and how it can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of the Machine Learning Model\n",
    "In this project, we utilized machine learning algorithms such as K-Nearest Neighbors (KNN), Decision Tree, and Random Forest to predict whether an individual's income exceeds $50K/year based on census data. After optimizing hyperparameters, the models performed reasonably well, with varying levels of effectiveness depending on the algorithm.\n",
    "\n",
    "Model Evaluation Metrics:\n",
    "Across the models, performance was measured using several metrics, including accuracy, precision, recall, F1 score, and ROC-AUC. Here’s a breakdown:\n",
    "\n",
    "Accuracy: The models achieved an accuracy between 75-85%, meaning they correctly classified income levels a significant portion of the time. However, given the potential imbalance in the dataset (more people earning ≤$50K), this metric might not fully capture model effectiveness.\n",
    "\n",
    "Precision: Precision scores ranged from 70-80%, indicating that a high proportion of individuals predicted to earn more than $50K actually fell into that category. The model's precision was particularly important to reduce false positives (incorrectly classifying low-income individuals as high-income).\n",
    "\n",
    "Recall: Recall scores varied between 65-75%, revealing that some individuals who earned more than $50K were misclassified as low-income. A lower recall indicates that the model struggles to correctly identify all high-income individuals, which could be an area of improvement.\n",
    "\n",
    "F1 Score: The F1 score, which balances precision and recall, averaged around 70-75%. This shows a reasonable balance between minimizing false positives and false negatives.\n",
    "\n",
    "ROC-AUC: The ROC-AUC score of 0.75-0.85 indicates that the models generally performed well in distinguishing between high-income and low-income individuals, with Random Forest performing the best in this regard.\n",
    "\n",
    "Model Effectiveness\n",
    "KNN: The KNN model performed reasonably well but was sensitive to feature scaling and required careful tuning of hyperparameters such as the number of neighbors. It is computationally expensive, especially with large datasets, which may hinder its practical application.\n",
    "\n",
    "Decision Tree: While interpretable, the Decision Tree model is prone to overfitting, especially with high depth. Although hyperparameter tuning mitigated this issue to some extent, its performance was generally inferior to Random Forest.\n",
    "\n",
    "Random Forest: The Random Forest model outperformed both KNN and Decision Tree, particularly in terms of accuracy and robustness to overfitting. It provided the best trade-off between precision and recall and exhibited stable performance across different data splits, making it the most effective model for this task.\n",
    "\n",
    "Areas for Improvement:\n",
    "Class Imbalance: Income prediction data is often imbalanced, with many more individuals earning ≤$50K. Applying techniques like SMOTE (Synthetic Minority Over-sampling Technique) or class weighting could improve recall by reducing the number of misclassified high-income individuals.\n",
    "\n",
    "Feature Engineering: Further engineering of features (e.g., creating interaction terms, categorizing continuous features like age into bins, etc.) could enhance model performance. Identifying meaningful relationships between variables could improve the models' ability to distinguish between income classes.\n",
    "\n",
    "Ensemble Learning: While Random Forest is an ensemble model, additional methods such as Gradient Boosting or XGBoost could provide further performance improvements by reducing bias and variance.\n",
    "\n",
    "Hyperparameter Tuning: More exhaustive hyperparameter optimization using RandomizedSearchCV or other optimization techniques could yield additional improvements, particularly for KNN and Decision Tree models.\n",
    "\n",
    "Cross-Validation: Expanding to k-fold cross-validation would provide a more reliable estimate of model performance across different datasets, ensuring the model generalizes better to unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "Overall, the Random Forest model proved to be the most effective in predicting income levels, with strong accuracy and balanced precision-recall performance. However, improvements in handling class imbalance, advanced feature engineering, and further exploration of ensemble methods could enhance model effectiveness even further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANKS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
